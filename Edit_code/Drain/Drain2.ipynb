{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khai báo sử dụng các thư viện. Thực hiện chạy ngay trên CPU, do đó, chỉ thực hiện mô phỏng, nếu ổn định sẽ thực hiện chạy trên kaggle\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sys\n",
    "\n",
    "import regex as re\n",
    "import os\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "import copy\n",
    "\n",
    "import glob # Thư viện mở rộng tên đường dẫn theo kiểu Unix\n",
    "\n",
    "from tabulate import tabulate # Thư viện sử dụng hiển thị dữ liệu dạng bảng cho DataFrame\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chỉnh sửa class Logcluster:\n",
    "from Root_Drain import LogParser, Node, Logcluster            # Source code cũ của Drain\n",
    "\n",
    "class Logcluster3(Logcluster):\n",
    "    \"\"\"\n",
    "    Class được chỉnh sửa lại, bao gồm một số thông số như sau:\n",
    "    \n",
    "    Thuộc tính:\n",
    "    ----------\n",
    "        - `logTemplate`: Template đặc trưng đại diện cho nhóm log đó, [\"The1\", \"the2\", ...]\n",
    "        - `logIDL`     : Danh sách các ID message log thuộc nhóm log trên, [1,2,3,4,5, ...] \n",
    "        - `levelL`     : Danh sách các Level (INFO, WARN, FATAL, ERROR) mà nhóm log có thể biểu diễn, [\"WARN\", \"INFO\", ...]\n",
    "        - `idTemplate` : Mã định danh của template đó, có thể bị thay đổi do template.\n",
    "        - `idLevelTemp`: Xác định mã định danh theo dạng {\"INFO\": \"L1\", ...} \n",
    "    \"\"\"\n",
    "    def __init__(self, logTemplate=\"\", levelL=None, logIDL=None):\n",
    "        self.logTemplate = logTemplate\n",
    "        if logIDL is None:\n",
    "            logIDL = []\n",
    "        self.logIDL = logIDL\n",
    "        self.levelL = list(levelL)\n",
    "        self.idTemplate = None\n",
    "        self.idLevelTemp = {\"TEMP\":None}\n",
    "        \n",
    "    def addIDLevel(self, logLevel):\n",
    "        self.levelL.append(logLevel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thực hiện chỉnh sửa lại 2 phương thức outputResult() và parser() của Drain:\n",
    "# Kế thừa Drain bằng cách tạo ra class Drain2:\n",
    "class LogParser2(LogParser):\n",
    "    \"\"\"\n",
    "    Kế thừa từ LogParser được sử dụng để thực hiện sửa đổi lại sao cho phù hợp.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)       # Đọc thêm: https://viblo.asia/p/python-args-va-kwargs-gDVK2pdnlLj\n",
    "        self.rootNode = Node()\n",
    "        self.list_logClust = []\n",
    "        self.list_eventsID = {}\n",
    "        self.df_TemplateL = None\n",
    "        self.list_counts = {\"TEMP\":0}\n",
    "    \n",
    "    def convert_unixtime(self, row):\n",
    "        \"\"\"\n",
    "        Phương thức trích xuất thời gian theo dạng chuẩn UNIX\n",
    "        \"\"\"\n",
    "        date_str = row[\"Date\"]\n",
    "        time_str = row[\"Time\"]\n",
    "        datetime_str = date_str[:2] + \"-\" + date_str[2:4] + \"-\" + date_str[4:] + \" \" + time_str[:2] + \":\" + time_str[2:4] + \":\" + time_str[4:]\n",
    "        unixtime = datetime.strptime(datetime_str, \"%m-%y-%d %H:%M:%S\").timestamp()\n",
    "        return int(unixtime)\n",
    "    \n",
    "    # def extract_block_id(self, parameter_list):\n",
    "    #     \"\"\"\n",
    "    #     Phương thức trích xuất blockID cho từng thông điệp log\n",
    "    #     \"\"\"\n",
    "    #     block_ids = []\n",
    "    #     pattern = re.compile(r'\\bblk_-?\\d+\\b')  # Biểu thức chính quy để tìm blockID\n",
    "    #     for param in parameter_list:\n",
    "    #         matches = pattern.findall(param)\n",
    "    #         if matches:  # Kiểm tra nếu tìm thấy blockID\n",
    "    #             block_ids.extend(matches)\n",
    "    #     return block_ids\n",
    "\n",
    "    def extract_block_id(self, parameter_list):\n",
    "        \"\"\"\n",
    "        Phương thức trích xuất blockID cho từng thông điệp log\n",
    "\n",
    "        Trả về:\n",
    "            - Chuỗi blockID đầu tiên được tìm thấy hoặc `NaN` nếu không tìm thấy.\n",
    "        \"\"\"\n",
    "        pattern = re.compile(r'\\bblk_-?\\d+\\b')  # Biểu thức chính quy để tìm blockID\n",
    "        for param in parameter_list:\n",
    "            matches = pattern.findall(param)\n",
    "            if matches:  # Kiểm tra nếu tìm thấy blockID\n",
    "                return matches[0]\n",
    "        return np.nan\n",
    "\n",
    "    # def extractByBlockID(self):\n",
    "    #     \"\"\"\n",
    "    #         Trích xuất ra quy trình template sử dụng theo BlockID\n",
    "    #     \"\"\"\n",
    "    #     unique_values = self.df_log['BlockID'].unique()\n",
    "    #     unique_values = [x for x in unique_values if pd.notna(x)]\n",
    "\n",
    "    #     res = {}\n",
    "\n",
    "    #     for value in unique_values:\n",
    "    #         filtered_df = self.df_log[self.df_log['BlockID'] == value].sort_values(by='UnixTime')\n",
    "    #         res[value] = filtered_df['IDLevel'].values.tolist()\n",
    "        \n",
    "    #     return res\n",
    "    \n",
    "    def extractByBlockID(self):\n",
    "        \"\"\"\n",
    "            Trích xuất ra quy trình template sử dụng theo BlockID\n",
    "        \"\"\"\n",
    "        unique_values = self.df_log['BlockID'].unique()\n",
    "        unique_values = [x for x in unique_values if pd.notna(x)]\n",
    "        \n",
    "        res = {block_id: [] for block_id in unique_values}\n",
    "        self.df_log = self.df_log.sort_values(by=\"UnixTime\")\n",
    "        \n",
    "        for idx, row in self.df_log.iterrows(): \n",
    "            level = row[\"IDLevel\"]\n",
    "            res[row[\"BlockID\"]].append(level)\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def outputResult(self, logClustL):\n",
    "        \"\"\"\n",
    "        Thực hiện in thông tin kết quả ra ngoài sau khi hoàn thành quá trình phân tích\n",
    "        \n",
    "        Tham số:\n",
    "        --------\n",
    "            - `logClustL`   : Danh sách các nhóm log đã thu thập được trong quá trình phân tách\n",
    "        \"\"\"\n",
    "        # ----------- Khai báo các biến sử dụng ----------#\n",
    "        log_templates = [0] * self.df_log.shape[0]\n",
    "        log_templateids = [0] * self.df_log.shape[0]\n",
    "        list_events = []                            # Mảng list_events lưu giữ các giá trị template\n",
    "        dictionary_events = self.list_eventsID      # Dictionary lưu giữ các đối tượng idTemplate và các thông số của nó: \"idTemplate\": {\"TEMP\":\"L5\", \"INFO\":\"I2\", ...}\n",
    "    \n",
    "        # --------------Thực hiện phân tích--------------#\n",
    "        # * Duyệt qua từng đối tượng Logcluster để thêm các giá trị vào từng biến trên\n",
    "        for logClust in logClustL:\n",
    "            template_str = \" \".join(logClust.logTemplate)\n",
    "            occurrence = len(logClust.logIDL)\n",
    "            template_id = hashlib.md5(template_str.encode(\"utf-8\")).hexdigest()[0:8]\n",
    "            logClust.idTemplate = template_id   # không cần cũng được\n",
    "            for logID in logClust.logIDL:\n",
    "                logID -= 1\n",
    "                log_templates[logID] = template_str\n",
    "                log_templateids[logID] = template_id\n",
    "            logClust.logIDL=[]\n",
    "            list_events.append([template_id, template_str, occurrence, logClust.levelL, logClust.idLevelTemp])\n",
    "            if template_id not in dictionary_events:\n",
    "                dictionary_events[template_id] = logClust.idLevelTemp\n",
    "\n",
    "        # DataFrame df_event lưu giữ các thông tin của Template\n",
    "        df_event = pd.DataFrame(\n",
    "            list_events, columns=[\"EventId\", \"EventTemplate\", \"Occurrences\", \"logLevel\", \"IDlogLevel\"]\n",
    "        )\n",
    "        # varL1.df_all_events = df_event\n",
    "        \n",
    "        # DataFrame df_log lưu giữ các thông tin của từng dòng thông điệp log\n",
    "        self.df_log[\"EventId\"] = log_templateids\n",
    "        self.df_log[\"EventTemplate\"] = log_templates\n",
    "        \n",
    "        # Chuyển đổi thời gian theo dạng UnixTime:\n",
    "        # Tạo thêm cột \"UnixTime\" trong DataFrame: df_log\n",
    "        self.df_log[\"UnixTime\"] = self.df_log.apply(self.convert_unixtime, axis=1)\n",
    "                \n",
    "        if self.keep_para:\n",
    "            self.df_log[\"ParameterList\"] = self.df_log.apply(\n",
    "                self.get_parameter_list, \n",
    "                axis=1\n",
    "            )\n",
    "        self.df_log[\"IDLevel\"] = self.df_log.apply(\n",
    "            lambda row: dictionary_events.get(row[\"EventId\"], {}).get(row[\"Level\"], None),\n",
    "            axis=1\n",
    "        )\n",
    "        self.df_log[\"LineId2\"] = self.df_log.apply(\n",
    "            lambda row: dictionary_events.get(row[\"EventId\"], {}).get(\"TEMP\", None),\n",
    "            axis=1\n",
    "        )\n",
    "        self.df_log[\"BlockID\"] = self.df_log[\"ParameterList\"].apply(self.extract_block_id)\n",
    "        \n",
    "        print(\"Thực hiện lấy kết quả BlockID\")\n",
    "        result_list = self.extractByBlockID2()\n",
    "        result_df = pd.DataFrame(list(result_list.items()), columns=['BlockID', 'Process'])\n",
    "        result_df['Process'] = result_df['Process'].apply(lambda x: ', '.join(map(str, x)))\n",
    "        \n",
    "        # self.df_log.to_csv(\n",
    "        #     os.path.join(self.savePath, self.logName + \"_structured.csv\"), index=False\n",
    "        # )\n",
    "        result_df.to_csv(\n",
    "            os.path.join(self.savePath, self.logName.replace('.log', '') + \"_process.csv\"),\n",
    "            index=False\n",
    "        )\n",
    "    \n",
    "    def parse(self, logName):\n",
    "        \"\"\"\n",
    "        Phương thức thực hiện quá trình phân tích log\n",
    "        \n",
    "        Tham số: \n",
    "        --------\n",
    "            - `logName`: Tên file đầu vào thực hiện phân tích\n",
    "        \"\"\"\n",
    "        print(\"File đầu vào: \" + os.path.join(self.path, logName))\n",
    "        start_time = datetime.now()\n",
    "        self.logName = logName\n",
    "\n",
    "        # ------Gán lại các đối tượng sử dụng--------#\n",
    "        rootNode = self.rootNode       # Địa chỉ Node gốc\n",
    "        logCluL = self.list_logClust   # Lưu giữ các đối tượng nhóm log Logcluster2 trước đó.\n",
    "        templateLogCluL = []           # Lưu giữ các template đã có trước đó.\n",
    "\n",
    "        # ----------------Load dữ liệu---------------#\n",
    "        self.load_data() \n",
    "\n",
    "        #-----------------Phân tích------------------#\n",
    "        # * Gán giá trị cho danh sách đếm template:\n",
    "        unique_Level = self.df_log[\"Level\"].unique()\n",
    "        for value in unique_Level:\n",
    "            if value not in self.list_counts:\n",
    "                self.list_counts[value] = 0\n",
    "\n",
    "        # * Thực hiện phân tích và lấy Template cho từng dòng thông điệp log\n",
    "        count = 0\n",
    "        for idx, line in self.df_log.iterrows(): \n",
    "            logLevel = str(line[\"Level\"])\n",
    "            logID = line[\"LineId\"]\n",
    "            logmessageL = self.preprocess(line[\"Content\"]).strip().split()  \n",
    "            matchCluster = self.treeSearch(rootNode, logmessageL)           \n",
    "            if matchCluster is None:\n",
    "                newCluster = Logcluster3(logTemplate=logmessageL, levelL=[logLevel], logIDL=[logID])\n",
    "                \n",
    "                # - Nếu có template mới, tạo ra, tăng biến đếm, gán id level template cho mẫu:\n",
    "                self.list_counts[\"TEMP\"] += 1\n",
    "                self.list_counts[logLevel] += 1\n",
    "                newCluster.idLevelTemp[\"TEMP\"] = \"L\"+ str(self.list_counts[\"TEMP\"])\n",
    "                newCluster.idLevelTemp[logLevel] = logLevel[0] + str(self.list_counts[logLevel])\n",
    "                \n",
    "                # - Thêm chúng vào cây phân tích\n",
    "                logCluL.append(newCluster)\n",
    "                self.addSeqToPrefixTree(rootNode, newCluster)\n",
    "            else:\n",
    "                # - Nếu template đã có:\n",
    "                newTemplate = self.getTemplate(logmessageL, matchCluster.logTemplate)\n",
    "                matchCluster.logIDL.append(logID)\n",
    "                # + Nếu có sự thay đổi trong template thành một template mới, cập nhật\n",
    "                if \" \".join(newTemplate) != \" \".join(matchCluster.logTemplate):\n",
    "                    matchCluster.logTemplate = newTemplate\n",
    "                    \n",
    "                # + Nếu có thêm một level mới biểu diễn template này, cập nhật nó\n",
    "                if logLevel not in matchCluster.levelL:\n",
    "                    matchCluster.addIDLevel(logLevel)\n",
    "                    self.list_counts[logLevel] += 1\n",
    "                    matchCluster.idLevelTemp[logLevel] = logLevel[0] + str(self.list_counts[logLevel])\n",
    "                    \n",
    "            count += 1\n",
    "            if count % 100000 == 0 or count == len(self.df_log):\n",
    "                print(\"Processed {0:.1f}% of log lines.\".format(count * 100.0 / len(self.df_log))) # Chỉ sửa mỗi vị trí này.\n",
    "\n",
    "        if not os.path.exists(self.savePath):\n",
    "            os.makedirs(self.savePath)\n",
    "        self.outputResult(self.list_logClust)\n",
    "        print(\"Phân tích hoàn thành! [Thời gian thực hiện: {!s}]\".format(datetime.now() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File đầu vào: ../../Dataset/HDFS/v1/HDFS_part1.log\n",
      "Total lines:  500000\n",
      "Processed 20.0% of log lines.\n",
      "Processed 40.0% of log lines.\n",
      "Processed 60.0% of log lines.\n",
      "Processed 80.0% of log lines.\n",
      "Processed 100.0% of log lines.\n",
      "Thực hiện lấy kết quả BlockID\n",
      "Phân tích hoàn thành! [Thời gian thực hiện: 0:01:18.685433]\n",
      "35\n",
      "500000\n",
      "{'TEMP': 35, 'INFO': 31, 'WARN': 4}\n"
     ]
    }
   ],
   "source": [
    "input_dir  = '../../Dataset/HDFS/v1/'   # Đường dẫn vào thư mục chứa file đầu vào\n",
    "output_dir = 'Result/'                  # Thư mục kết quả\n",
    "log_file   = 'test2.log'                 # Tên file đầu vào\n",
    "log_format = '<Date> <Time> <Pid> <Level> <Component>: <Content>'  # HDFS log format\n",
    "# Biểu thức chính quy\n",
    "regex      = [\n",
    "    r'blk_(|-)[0-9]+' , # block id\n",
    "    r'(/|)([0-9]+\\.){3}[0-9]+(:[0-9]+|)(:|)', # IP\n",
    "    r'(?<=[^A-Za-z0-9])(\\-?\\+?\\d+)(?=[^A-Za-z0-9])|[0-9]+$', # Numbers\n",
    "]\n",
    "st         = 0.5  # Ngưỡng tương đồng\n",
    "depth      = 4  # Độ sâu của cây phân tích\n",
    "\n",
    "parserObj = LogParser2(log_format, indir=input_dir, outdir=output_dir, depth=depth, st=st, rex=regex)\n",
    "# parserObj.parse(log_file)\n",
    "\n",
    "selected_columns = ['LineId', 'UnixTime', 'Level', 'EventId', 'EventTemplate', 'IDLevel', 'LineId2', 'ParameterList', 'BlockID']\n",
    "# for i in range(1,6):\n",
    "#     str_file = \"test\"+str(i)+\".log\"\n",
    "#     parserObj.parse(str_file)\n",
    "#     print(len(parserObj.list_logClust))\n",
    "#     print(parserObj.list_counts)\n",
    "#     # outputResult2(parserObj.list_logClust)\n",
    "#     # parserObj.df_log.loc[:, selected_columns].head(60)\n",
    "#     parserObj.df_log = pd.DataFrame()\n",
    "\n",
    "parserObj.parse(\"HDFS_part1.log\")\n",
    "print(len(parserObj.list_logClust))\n",
    "print(len(parserObj.df_log))\n",
    "print(parserObj.list_counts)\n",
    "# parserObj.df_log.loc[:, selected_columns].head(60)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc file gắn nhãn bất thường cho trước:\n",
    "anomaly_df = pd.read_csv(\"HDFS.anomaly_label.csv\")\n",
    "anomaly_df.rename(columns={anomaly_df.columns[0]: \"BlockID\"}, inplace=True) # Đổi tên cột\n",
    "\n",
    "# Đọc dữ liệu các DataFrame BLockID ghi lại tiến trình và cho vào một DataFrame:\n",
    "file_list = glob.glob('./Result/*.csv')\n",
    "df_list = [pd.read_csv(file) for file in file_list]\n",
    "full_df = pd.concat(df_list, ignore_index=True)\n",
    "process_df = full_df.groupby('BlockID')['Process'].apply(lambda x: ', '.join(x)).reset_index()\n",
    "process_df['Process'] = process_df['Process'].apply(lambda x: x.split(', '))\n",
    "\n",
    "print(len(process_df))\n",
    "\n",
    "print(len(anomaly_df))\n",
    "\n",
    "# Gộp 2 DataFrame thành 1 theo cột BLockId\n",
    "merged_df_left = pd.merge(anomaly_df, process_df, on='BlockID', how='outer')\n",
    "merged_df_left.to_csv(\n",
    "            os.path.join(\"./Result\",\"blockID_process.csv\"),\n",
    "            index=False\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Đọc dữ liệu DataFrame từ nhiều file và gộp thành 1:\n",
    "# file_list = glob.glob('./Test/*.csv')\n",
    "# df_list = [pd.read_csv(file) for file in file_list]\n",
    "# full_df = pd.concat(df_list, ignore_index=True)\n",
    "# grouped_df = full_df.groupby('BlockID')['Process'].apply(lambda x: ', '.join(x)).reset_index()\n",
    "# grouped_df['Process'] = grouped_df['Process'].apply(lambda x: x.split(', '))\n",
    "\n",
    "# print(len(grouped_df))\n",
    "# grouped_df.head(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
